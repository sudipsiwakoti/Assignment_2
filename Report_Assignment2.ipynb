{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudipsiwakoti/ML2019_ID_12956936_Assignment_2/blob/master/Report_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8UQ1L1ofdUW",
        "colab_type": "text"
      },
      "source": [
        "# **Practical Machine Learning Project**\n",
        "# **Melbourne House Price Prediction**\n",
        "\n",
        "## **31005 | Assignment 2**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Student ID: 12956936\n",
        "### Student Name: Sudip Siwakoti\n",
        "\n",
        "link to Github: https://github.com/sudipsiwakoti/ML2019_ID_12956936/blob/master/report.ipynb\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hg8Lg8rga3F",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "The purpose of this report is to give the overview of the machine learning process implemented using python which can be found at (https://github.com/sudipsiwakoti/Assignment_2.git) GitHub repository. Along with the overview it will also give details on problem definitions, challenges, and algorithms implemented, results and performance and comparison of the algorithms used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htLePNZ8ggGU",
        "colab_type": "text"
      },
      "source": [
        "# Problem Definition\n",
        "The problem presented in this report is the problem of house price prediction for a city or state and for the purpose of the project the dataset used was taken from Kaggle website for Melbourne, Australia (https://www.kaggle.com/anthonypino/melbourne-housing-market/activity). Since it is not practical to define a problem by ability to predict exact price of the house, my problem definition for the project was to test if it was possible to predict the price of the house within (+/- 20,000) range at a confidence of 95%. Based on my research of the housing market in Australia both buyers and sellers have to rely on agents to get pricing information about a property and market price can be artificially inflated but being able to see price with significant confidence of 95% can be helpful for making a purchase decision or for bidding in an auction. The ability to predict property prices with such higher confidence will give first home buyers a confidence toward their purchase decision. The reason for selecting price range of +/- A$ 20,000 at a confidence level of 95% is due to the fact that houses prices are significantly disproportionate due to various factors that affect the house prices in the market which ranges from building material used to interior layout which is hard to incorporate in a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9peZtzHgmcI",
        "colab_type": "text"
      },
      "source": [
        "# Challenges\n",
        "Various challenges were encountered during the process of this project. First challenge was encountered in the beginning of the project on handling missing data. There was large amount of missing data and selection best method to handle missing data was important not to bias the model. To select best method to handle missing data different available method were used (e.g. panda's interpolation, filling NA/0 or removing) based on different experimentation and results of prediction, removing rows was concluded to be the best method and used to build final model. Second challenge faced during the project was processing outlier. This was a significant challenge as there were huge outlier in the dataset and we had to be careful not to remove real data that posed as an outlier while also removing outlier and bad data. To overcome this challenge, I used pair plot and visualisation along with manual data inspection to select conditions to remove outliers while not biasing the results.\n",
        "\n",
        "The whole project was completed in three stages\n",
        "\n",
        "## Stage 1: \n",
        "In this stage I defined the problem and set test criteria and explored the data. during the exploration phase I created different visualisation to get insight of data and then noted key areas of interest. I also implemented prediction model on raw data to set a benchmark from the raw data to compare it with my final prediction (This benchmark is not included as part of report). In this stage, I verified effect of each attributes on model to create a data pipeline. \n",
        "    \n",
        "## Stage 2:\n",
        "Based on the insight gained form the initial exploration and visualisation I commenced data pre-processing and prepared data for feature extraction using different methods. Here LassoCV was used to extract best feature for linear regression model while Decision Tree classifier and random forest classifier was used to extract feature for decision tree model and random forest model respectively. Based on the feature presented by feature extractor attributes were selected and prediction was made.\n",
        "\n",
        "\n",
        "\n",
        "## Stage 3:\n",
        "In this stage of the process difference absolute mean was calculated to verify the quality of the prediction while absolute difference between actual price and predicted price was calculated and subjected to 1 sample t-test to test the hypothesis if or not our  prediction was within acceptable margin. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjpuu6mUgovB",
        "colab_type": "text"
      },
      "source": [
        "# \n",
        "After reading through the paper, I have developed a mixed sentiment to the technical quality of the paper. Firstly, talking about the quality of the results are of high standards as they have used the error rate of test set rather than training set but I would have loved to see training sets error rate as well as this would have given me additional information on the method they have implemented. Secondly, they have taken extra steps to compare their findings with large number of classifiers to validate the results. Along with that they also compared their classifier with modified version of the classifier and one of the example was implementing boosting with LeNet4 for better results. Intention of their conclusion from the experiment was not demote any other classifier as incapable but rather they suggested on how implementation of Gradient based learning and GTN along with other classifier can optimise the system. This process can be seen in the experiment in section X where they implement different methods to achieve better results for Check Reading System. My only criticism on the technical quality is that if the article had included segmented system diagram with code snippet used would have made the experiment easier to recreate by any person reading it. Based on my level of understanding, I would not be able to recreate the experiments just based on the literature presented in the paper. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHmVz3XlgxPT",
        "colab_type": "text"
      },
      "source": [
        "# Algorithms \n",
        "The algorithm for house price prediction is presented in figure 1 shows that the data set was initially pre-processed to remove any impurities present in the data which was then spited into data label and data attributes. Price was selected as data label as these items were to be predicted while every other remaining label were selected as attributes for feature selection. After processing attributes through feature selection model best features were fed into prediction model which was then used to predict house prices. The result was then used to calculate the difference and further subjected to 1-Sample t-test to verify my hypothesis of the prediction. \n",
        "\n",
        "\n",
        "**Algrothim Implementation process**\n",
        "\n",
        "![](https://raw.githubusercontent.com/sudipsiwakoti/ML2019_ID_12956936_Assignment_2/master/Algrothim.jpg)\n",
        "\n",
        "Fig 1. *Algorithms of process flow.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6qrTuWVhARl",
        "colab_type": "text"
      },
      "source": [
        "#  Evaluation\n",
        "Based on the prediction results received from the model it can be concluded that the project was unsuccessful as all three-machine learning model where not able to predict house prices to satisfy my acceptance criteria/ accuracy. Though the presented model were not successful I was able to conclude based on my results that linear and decision tree model are not good machine learning model to predict house prices while Random forest seem to be much more better model but the caveat is that it is computationally expensive. Random forest model had significantly higher accuracy. For Random forest model both absolute mean error and p-value of difference between actual price and predicted price was significantly better and had potential. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IaxvUHRjqol",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "Based on the results, though I was not able to predict house prices it has given me opportunity to further investigate with other model in future. While saying that, the quality and quantity of the data was not good enough as more than 3 quarter of the data was lost during the pre-processing stage. To improve the model accuracy, we could feature engineer new features to reduce data loss during pre-processing. Also, I would purpose testing the dataset with other models like neural network to improve accuracy. Along with that dataset also lacked price associated features like condition of the property, renovation date, property features, etc which could be valuable. Another key method to improve accuracy of the prediction is to predict house, unit and townhouse separately as their pricing structure differs significantly based on unique features that are not interrelated. "
      ]
    }
  ]
}